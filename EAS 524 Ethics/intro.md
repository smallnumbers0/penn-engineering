The Bhopal disaster was a catastrophic industrial accident caused by equipment failures, poor safety standards, and complex questions of responsibility.

**Notes on the Bhopal Disaster Video** 

**Overview of the Incident** 

- On December 2, 1984, in Bhopal, India, water leaked into a tank containing 10,000 gallons of methyl isocyanate (MIC), causing a rapid, exothermic reaction.
- By 1:00 AM, over 30 tons of toxic MIC gas were released into the air, spreading into nearby slums and across the city.
- The disaster killed more than 15,000 people and permanently injured over 500,000, making it the worst industrial accident in history.

**Background and Contributing Factors** 

- Union Carbide, a major chemical manufacturer, produced a pesticide called Sevin, with MIC as a key ingredient.
- The Bhopal plant was intended to be a copy of a safer, modern plant in West Virginia, but $8 million in budget cuts led to the omission of critical safety systems.
- Safety systems missing or offline included computerized controls, refrigeration units, vent gas scrubbers, and flame towers.
- Previous accidents at the plant (1981, 1982) were linked to poor training and safety lapses.
- An illegal slum developed next to the plant, increasing the population at risk.

**The Night of the Disaster** 

- Staff noticed a pressure increase in an MIC tank but initially dismissed it as a sensor malfunction.
- A leak was found around 11:40 PM, but staff took a scheduled tea break instead of responding immediately.
- An evacuation alarm was briefly sounded but then turned off for unclear reasons.
- By the time staff returned, the situation was critical; a relief valve burst, releasing the toxic gas cloud.

**Aftermath and Responsibility** 

- The gas spread while most people were asleep, causing mass casualties and injuries.
- Lawsuits were filed within days; the Indian government sued on behalf of citizens, resulting in a $470 million settlement (considered small for the scale of the disaster).
- Litigation over the settlement continued for decades.

**Causes and Unanswered Questions** 

- The immediate cause was water entering the MIC tank, but how it happened remains unclear (accident, negligence, or sabotage).
- Union Carbide suggested sabotage, but regardless, the plant’s design should have accounted for such risks.
- Multiple failures: poor training, inadequate safety systems, ignored warnings, and risky plant location.
- Raises complex questions about responsibility: Is everyone responsible, or does shared responsibility mean no one is? What if it was just an accident or sabotage?

**Ethical Takeaways** 

- In engineering, when everyone is responsible, no one is—so vigilance and personal responsibility are crucial.
- Acting responsibly means adhering to the highest professional standards to prevent disasters.
- The Bhopal case is used to provoke thought about responsibility, causation, and the ethical duties of engineers.

**Final Thoughts** 

- The disaster’s complexity lies in the interplay of technical, human, and societal failures.
- The video encourages ongoing reflection on responsibility and ethical conduct in engineering and beyond.

**Three Mile Island Lecture Notes** 
**Nuclear Power’s Promise & Reality:**  
- In the 60s/70s, everyone thought nuclear energy was the future—almost 200 reactors approved in the US, with predictions of 1,000+ by 2000. But after Three Mile Island (TMI) in 1979, only 93 reactors are running today, and most are old.
**What Happened at TMI:**  
- TMI is near Harrisburg, PA, with two reactors (TMI-1 and TMI-2). TMI-2 had a partial meltdown less than a year after starting up.  
- Nuclear reactors use fission to heat water, make steam, and spin turbines for electricity. Control rods manage how much heat is produced.  
- The big risk: if the fuel gets too hot, it can melt and release radioactive stuff.
**The Accident Sequence:**

- March 28, 1979, 4:00 AM: Water pump fails, reactor shuts down (as it should).
- Even shut down, the core needs cooling.
- Pressure relief valve opens to release steam, but gets stuck open.
- Control room light doesn’t show the valve is stuck, so operators don’t realize coolant is leaking.
- For two hours, operators think everything’s fine, don’t add water.
- Eventually, they figure it out, close the valve, and add water—but the core is exposed by then.
- Adding cold water cracks the superhot fuel rods, releasing radioactive material and hydrogen gas.
- Only option: vent the gas into the atmosphere.
- Voluntary evacuation for 140,000 people in a 20-mile radius for a few weeks.
- Actual radiation released was low—like a couple X-rays over a year—but public trust in nuclear energy was shattered.

- **Key Lessons:**

- Modern reactors are designed to fail safely, not needing active cooling in emergencies.
- TMI changed how people see nuclear power—one accident can change everything.
- Blaming operators isn’t enough; complex systems are prone to “normal accidents” (Perrow’s idea). Small errors can snowball.
- Instead of expecting perfection, we need systems that can handle mistakes and recover.
- The control room was a mess—too much info, not enough clarity for operators. Now, design focuses on giving the right info at the right time.

- **Big Takeaway:**  
    TMI is a warning about how complicated systems can go wrong in unexpected ways. We need to design for resilience, not just prevention, and remember that technology, people, and society are all tangled up together. It’s not just about fixing one thing—it’s about being ready for the unexpected.

The FAA was created to ensure safe, efficient, and standardized air travel through federal regulation.

**Notes on the FAA Lecture** 

The FAA (Federal Aviation Administration) is a federal regulatory agency created in 1958 to oversee and promote civil aviation safety and efficiency in the United States. Its mission is to provide the safest, most efficient aerospace system in the world.

**Why the FAA Exists** 
- **Safety and Efficiency:**  
The FAA’s main goals are to prevent crashes and make air travel safe and efficient for both civil and military aircraft.
- **Regulation and Promotion:**  
It regulates the aviation sector, sets standards, and promotes the industry’s growth.

**Early Aviation Regulation** 

- **1920s:**  
Commercial aviation began to grow, but safety concerns were high. The industry itself asked Congress for regulation to build public trust.
- **Air Commerce Act of 1926:**

- Created pilot licensing and aircraft certification.
- Established standard rules (e.g., “drive on the right side of the air”).
- Installed navigation aids (lights, beacons).
- Administered by the Department of Commerce.

- **Limitations:**  
These early regulations focused on pilots and aircraft, not the industry as a whole.

**Major Accidents and Regulatory Changes** 

- **1931:**  
Notre Dame football coach Newt Rockne died in a crash due to a design flaw (plywood delaminated when wet).
- **1935:**  
Senator Bronson Cutting died in another crash, prompting Congress to act.
- **Civil Aeronautics Act of 1938:**

- Created the Civil Aeronautics Administration (CAA) and Civil Aeronautics Board (CAB).
- Regulated airline routes, fares, and market entry.

- **1956:**  
United Airlines and TWA planes collided over the Grand Canyon, killing 128 people.

- Led to the creation of the Federal Aviation Agency (later Administration) via the Federal Aviation Act of 1958.

**What the FAA Does** 

- **Safety Primacy:**  
Safety is the top priority in all FAA activities.
- **Air Traffic Control:**  
Manages both civilian and military airspace.
- **Airport Regulation:**  
Oversees airport construction, management, and personnel.
- **Standardization:**  
Enforces rules and standards to keep aviation safe and organized.

**Lessons from FAA History** 

- **Safety Regulation is Crucial:**  
Early efforts weren’t enough; regulation had to grow with the industry.
- **Public Trust:**  
Aviation is extremely safe in the U.S., which is vital for public confidence.
- **Standardization Matters:**  
Clear, enforced standards (like driving on the right side) prevent chaos and accidents.
- **Regulation is Often Reactionary:**  
Major changes usually follow high-profile accidents or political pressure, not just technical needs.
- **Industry Influence:**  
Sometimes regulation serves industry interests (e.g., keeping competitors out) as much as public safety.

**Big Takeaways** 

- The FAA is a case study in how government regulation can make a dangerous technology safe and trustworthy.
- Regulation must evolve with technology and public needs, not just react to disasters.
- Standardization and enforcement are key to safety.
- There’s a tension between technical realities, public perception, and political influence in how regulations are made and enforced.
- The FAA’s story is a reminder that safety, trust, and efficiency in complex systems require constant vigilance and adaptation.


The Surfside condominium collapse exposed deep issues in building safety, maintenance, and legal responsibility.

**Notes on the Surfside Condominium Collapse Video** 

On June 24, 2021, the Champlain Towers South in Surfside, Florida—a 12-story condo building—partially collapsed, killing 98 people and injuring dozens more. The building was destroyed. The cause is still under investigation, with a full NIST report expected in summer 2025, but several factors are already clear.

**Building Details and Known Problems** 

- Built in 1981, the condo had a large concrete pool deck above a parking garage, with heavy planters (up to 3 tons each).
- There were longstanding drainage and waterproofing issues. Water pooled on the deck, leaked into the garage, and caused visible concrete damage and corrosion, even exposing rebar.
- A 2018 engineering report warned that failed waterproofing was causing major structural damage and that not fixing it would make things exponentially worse.
- The condo board knew about these problems, but repairs were not made in time.

**Collapse Sequence and Uncertainties** 

- The pool deck’s failure shouldn’t have caused the whole building to collapse, as it was adjacent, not directly under the main structure.
- Possible contributing factors:

- The collapse may have pushed columns over, or the columns themselves may have already been weakened.
- Heavy planters, not in the original design, may have added stress.
- Construction work on the deck just before the collapse could have played a role.

- Preliminary NIST findings: Some structural columns under the pool deck didn’t meet 1979 building codes. It’s unclear if this alone caused the collapse or if similar issues existed throughout the building.

**Legal and Ethical Questions** 

- Condominiums are owned collectively by unit owners, each with a small share. A board elected by owners manages maintenance.
- Who is responsible for the collapse? The current board? Past boards? The original builders? Owners from 15 years ago?
- Can current owners sue past owners or builders? If so, what does that mean for future owners and property values?
- If many buildings in the area have similar code issues, should they all be condemned? What happens to property values and community savings?
- If building codes themselves were insufficient, who is at fault?

**Broader Implications** 

- NIST’s role is not to assign blame but to learn and improve building codes to prevent future tragedies.
- Legal, insurance, and political interests may have different priorities—assigning blame, compensation, or changing laws.
- The tragedy is more common and less sensational than disasters like Bhopal or Three Mile Island, but it’s more likely to affect ordinary people.
- Raises questions about the responsibilities of non-expert homeowners, boards, and the broader community in maintaining safety.

**Final Thoughts** 

The Surfside collapse is a complex tragedy, involving technical failures, maintenance lapses, and difficult questions about responsibility and liability. It highlights the need for vigilance, better standards, and a more proactive approach to safety—especially in settings where ordinary people, not just engineers or corporations, are responsible for the well-being of a community.



The trolley problem is a classic ethical dilemma exploring choices, consequences, and moral reasoning in real life.

**Notes on The Trolley Problem Lecture** 

The trolley problem, introduced by philosopher Philippa Foot in 1967, is a thought experiment that frames ethical dilemmas in a simple but powerful way. The basic scenario: a trolley is headed toward five people tied to the track. You can flip a switch to divert it to another track, where only one person is tied. If you act, one dies; if you do nothing, five die. Most people say they’d flip the switch, favoring the utilitarian logic of saving more lives.

But the problem gets more complicated. If you’re a doctor with five patients needing organ transplants and a healthy patient arrives, would you sacrifice one to save five? Most people reject this, even though the numbers are the same. Why is the doctor scenario different from the trolley?

The lecture pushes us to consider:

- Does it matter who the people are? (age, relationship, social value, etc.)
- What if the trade-off is probabilistic, not certain?
- How do these dilemmas play out in real-world settings, like chemical plants or nuclear power stations, where decisions about risk and cost can affect lives?

The trolley problem forces us to ask:

- Is there a moral difference between action and inaction?
- Are utilitarian calculations enough, or are there moral absolutes?
- Can breaking a law ever be justified if it saves lives?

The problem is a tool for thinking about ethics from different perspectives—engineer, manager, bystander, or even someone directly affected. The lecture encourages us to apply the trolley problem to previous case studies (Bhopal, Three Mile Island, Surfside) and to our own lives and work. Once you start seeing trolley problems, you may notice them everywhere.

Finally, the lecture asks: how useful is the trolley problem for engineers and real-world decision-making? This question will be explored in the next video.

Engineering ethics is shaped by society’s values, not just personal moral philosophy.

**Notes on “Political vs. Moral Values” Lecture** 

This lecture wraps up the module’s case studies and pivots from personal moral philosophy to the broader social context of engineering ethics. The main message: while tools like the trolley problem help us think about ethical dilemmas, the real world of engineering is governed by society’s judgments, not just individual virtue.

**Key Points** 

- **Case Studies and Ethical Tools:**  
- The module used famous disasters (Bhopal, Three Mile Island, Surfside) and the trolley problem to introduce ethical thinking. These help us see issues from different perspectives and understand what it means to be a good or moral person.
- **Limits of Moral Philosophy in Engineering:**  
- The trolley problem and virtue ethics are useful for personal growth and reflection, but they don’t decide what is ethical in engineering practice.  
- Society, not engineers, determines what is considered ethical. If society dislikes a technology, even the most virtuous engineer’s work can be rejected or condemned.
- **Role of the Engineer:**  
- Most engineers aren’t in positions to make big design decisions that will be judged by society.  
- However, every engineer has a responsibility to raise ethical concerns when they see them, even if they don’t have the final say.  
- Example: NASA engineers tried to stop the Challenger launch due to safety concerns. They were right, and their efforts mattered—even if the disaster wasn’t prevented.
- **Societal Judgment and Consequences:**  
- Public reaction shapes the fate of technologies and industries.

- Nuclear accident (Three Mile Island) led to decades of distrust in nuclear power.
- Aviation accident (senator killed) led to sweeping regulation.
- Industrial accident (Bhopal) led to new laws and lawsuits.

- **Engineering Ethics as Social Understanding:**  
- Ethics in engineering is about understanding the role of engineers in society, not just about being a good person.  
- It’s about navigating the complex relationship between individual values, societal expectations, and the law.
- **Virtue Ethics Still Matters:**  
- Studying moral philosophy makes you a more thoughtful and conscientious person.  
- It helps you understand your own work and the decisions of others.
- **Course Focus Going Forward:**  
- The rest of the class will look at ethics from the perspective of society and the state.  
- It will explore the relationship between citizens, the law, and technology, and how public and private interests interact.

**Final Thoughts** 

Ethical engineering isn’t just about personal virtue or philosophical puzzles—it’s about how your work fits into society’s values and legal frameworks. The challenge is to understand and navigate these forces, knowing that public perception and law often outweigh individual intentions. The module sets the stage for deeper exploration of how engineers, citizens, and the state interact in shaping technology and its impact.